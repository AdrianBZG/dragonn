{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train your DragoNN tutorial 5: \n",
    "## CNN Hyperparameter Tuning via Grid Search \n",
    "This tutorial is a supplement to the DragoNN manuscript and follows figure 6 in the manuscript. \n",
    "\n",
    "This tutorial will take 30 minutes - 1 hour if executed on a GPU.\n",
    "\n",
    "## Outline<a name='outline'>\n",
    "<ol>\n",
    "    <li><a href=#1>How to use this tutorial</a></li>\n",
    "    <li><a href=#2>Data simulation and default CNN model performance</a></li>\n",
    "    <ol>\n",
    "        <li><a href=#2a>Simple Motif Detection: TAL1, CTCF, ZNF143, SIX5 </a></li>\n",
    "        <li><a href=#2b>Motif Density Detection</a></li>\n",
    "        <li><a href=#2c>Motif Density Localization</a></li>\n",
    "        <li><a href=#2d>Multiple Motif Detection</a></li>\n",
    "        <li><a href=#2e>Heterodimer Motif Grammar: SPI1_IRF</a></li>\n",
    "    </ol>\n",
    "    <li><a href=#3>Training examples</a></li>\n",
    "    <li><a href=#4>Convolutional Filter Width </a></li>  \n",
    "    <li><a href=#5>Number of convolution filters</a></li>\n",
    "    <li><a href=#6>Max Pooling Width</a></li>\n",
    "</ol>\n",
    "Github issues on the dragonn repository with feedback, questions, and discussion are always welcome.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this tutorial<a name='1'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "This tutorial utilizes a Jupyter/IPython Notebook - an interactive computational enviroment that combines live code, visualizations, and explanatory text. The notebook is organized into a series of cells. You can run the next cell by cliking the play button:\n",
    "![play button](./primer_tutorial_images/play_button.png)\n",
    "You can also run all cells in a series by clicking \"run all\" in the Cell drop-down menu:\n",
    "![play all button](./primer_tutorial_images/play_all_button.png)\n",
    "Half of the cells in this tutorial contain code, the other half contain visualizations and explanatory text. Code, visualizations, and text in cells can be modified - you are encouraged to modify the code as you advance through the tutorial. You can inspect the implementation of a function used in a cell by following these steps:\n",
    "![inspecting code](./primer_tutorial_images/inspecting_code.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment the lines below if you are running this tutorial from Google Colab \n",
    "#!pip install https://github.com/kundajelab/simdna/archive/0.3.zip\n",
    "#!pip install https://github.com/kundajelab/dragonn/archive/keras_2.2_tensorflow_1.6_purekeras.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure our results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading dragonn's tutorial utilities and reviewing properties of regulatory sequence that transcription factors bind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dragonn tutorial utilities \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from dragonn.tutorial_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data simulation and basic architecture performance <a name='2'>\n",
    "<a href=#outline>Home</a>\n",
    "\n",
    "\n",
    "DragoNN provides a set of simulation functions. Let's use the **print_available_simulations** function to examine the list of simulations supported by DragoNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulate_differential_accessibility\n",
      "simulate_heterodimer_grammar\n",
      "simulate_motif_counting\n",
      "simulate_motif_density_localization\n",
      "simulate_multi_motif_embedding\n",
      "simulate_single_motif_detection\n"
     ]
    }
   ],
   "source": [
    "print_available_simulations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We design four single-task binary classification tasks using DNA sequences that simulate different\n",
    "properties of regulatory DNA sequences: single motif, homotypic motif clusters, heterotypic motif\n",
    "clusters, and heterodimer motif grammars with spatial constraints. We further design a multitask\n",
    "classification simulation to jointly detect motif instances of 3 distinct TFs (corresponding to 3 binary\n",
    "classification tasks, one per TF). In each simulation, we embed motif instances with the relevant\n",
    "constraints in random sequences (G/C frequency = 0.4). We hold out 20% of sequences for a test\n",
    "set, 16% for a validation set, and use the remaining sequences for training. Motif instances are\n",
    "reverse complemented with 0.5 probability before they are embedded in the background sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Motif Detection: \n",
    "\n",
    "TAL1_Known4: \n",
    "![play button](./primer_tutorial_images/TAL1_known4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tal1_parameters = {\n",
    "    \"motif_name\": \"TAL1_known4\",\n",
    "    \"seq_length\": 500, \n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\": 0.4}\n",
    "tal1_data = get_simulation_data(\"simulate_single_motif_detection\",\n",
    "                                      tal1_parameters,\n",
    "                                      validation_set_size=640, test_set_size=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CTCF_Known1: \n",
    "![play button](./primer_tutorial_images/CTCF_known1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcf_parameters = {\n",
    "    \"motif_name\": \"CTCF_known1\",\n",
    "    \"seq_length\": 500, \n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\": 0.4}\n",
    "ctcf_data = get_simulation_data(\"simulate_single_motif_detection\",\n",
    "                                      ctcf_parameters,\n",
    "                                      validation_set_size=640, test_set_size=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZNF143_known2: \n",
    "![play button](./primer_tutorial_images/ZNF143_known2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "znf143_parameters={\n",
    "    \"motif_name\": \"ZNF143_known2\",\n",
    "    \"seq_length\": 500,\n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\":0.4\n",
    "}\n",
    "znf143_data=get_simulation_data(\"simulate_single_motif_detection\",\n",
    "                               znf143_parameters,\n",
    "                               validation_set_size=640,test_set_size=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIX5_known1:  \n",
    "![play button](./primer_tutorial_images/SIX5_known1.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "six5_parameters={\n",
    "    \"motif_name\": \"SIX5_known1\",\n",
    "    \"seq_length\": 500,\n",
    "    \"num_pos\": 10000,\n",
    "    \"num_neg\": 10000,\n",
    "    \"GC_fraction\":0.4\n",
    "}\n",
    "six5_data=get_simulation_data(\"simulate_single_motif_detection\",\n",
    "                               six5_parameters,\n",
    "                               validation_set_size=640,test_set_size=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Density Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this binary simulation task, we simulate 10K 500 bp random sequences with 0-2 instances of a TAL1 motif embedded at any random position and\n",
    "10K 500 bp random sequences with 3-5 instances of the motif embedded at any random position. To solve this simulation, the model needs to learn the differences in motif counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif Density Localization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this binary simulation task, we simulate 20K random sequences of length 1 Kbp with 2-4 embedded instances of the TAL1 motif. In the positive set of 10K sequences, the motif instances are embedded in the central 150bp. The negative set of 10K sequences, contain embedded motif instances at any random position. To solve this simulation, the model needs to learn localization differences of the motif instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Motif Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simulation of multiple co-binding TFs, we simulate 20K 500 bp random sequences. For each sequence, we independently embed 0 or 1 instance of motifs corresponding to 3 TFs: CTCF, ZNF143, and SIX5 (See SM). Each sequence has binary labels for 3 tasks corresponding to the presence/absence of a motif instance of each of the three TFs. We train a multitask CNN such as that the last layer of the model now has three output logistic neurons corresponding to the three separate tasks. To solve this simulation, the model needs to detect all three motifs while sharing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heterodimer Motif Grammar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this binary simulation task, we simulate 20K 500 bp random sequences with one instance of an SPI1 motif and one instance of an IRF motif\n",
    "32(See SM). In the positive set of 10K sequences, the pair of motifs are embedded with a relative spacing of 2-5 bp between each other, at any random position in each sequence. In the negative set, the pair of motifs are both randomly embedded with no positional or spacing constraints. To solve this simulation, the model needs to detect both motifs and learn the spacing constraint between them in the positive set. For this simulation, an architecture with a single convolutional layer does not perform well (results not shown). Hence, we use a reference architecture with 3 convolutional layers. Each convolutional layer has 15 filters (size 15, stride 1) and ReLU-non-linearity, followed by max-pooling (size 35, stride 35), followed by a fully connected layer with sigmoid non-linearity for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a simple reference CNN architecture that contains a convolutional layer with 10 convolutional filters (size 15, stride 1) and ReLU activations, followed by max-pooling (size 35,stride 35), followed by a fully connected layer with a logistic output neuron for binary classification. Models are trained using the Adam optimizer with early stopping after 7 consecutive epochs without validation loss improvement. Performance (auROC) is recorded on an the independent test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then systematically vary the number of training examples, size of convolutional filters, number of convolutional filters and size of max pooling to understand the impact of these hyperparameters on prediction performance for each of the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
